{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of MITx ICU Mortality Skeleton.ipynb",
      "private_outputs": true,
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/artexmg/186501xStatistics/blob/master/MIT_ICU_Mortality_Skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ElpqUAmUvI7w"
      },
      "source": [
        "from google.colab import auth\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, roc_auc_score, roc_curve, confusion_matrix, f1_score\n",
        "\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIyJAXiowph8"
      },
      "source": [
        "## Loading Data\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nbm57eDfvNVO"
      },
      "source": [
        "auth.authenticate_user()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kyBjR6vPXpNd"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_QLGMNMKvwIx"
      },
      "source": [
        "#### Lab Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x15yHLWbvOcd"
      },
      "source": [
        "!gsutil cp gs://mlhc-mimic/adult_icu.gz ./\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Lq03V-vhzW"
      },
      "source": [
        "lab_df = pd.read_csv('adult_icu.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4j84nlbOwAYH"
      },
      "source": [
        "#### Note Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d6s5t1m_wDMj"
      },
      "source": [
        "!gsutil cp gs://mlhc-mimic/adult_notes.gz ./\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oiwcD0kJwJkQ"
      },
      "source": [
        "note_df = pd.read_csv('adult_notes.gz')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KM0ahN5-YGT4"
      },
      "source": [
        "print(f'rows lab_def: {len(lab_df)}')\n",
        "print(f'rows adult_notes: {len(note_df)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RAknECuC8tvw"
      },
      "source": [
        "## Question 2\n",
        "\n",
        "Predicting hospital mortality from lab values\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hz2dCQJL8u3J"
      },
      "source": [
        "##TODO: Explore the dataset lab_df"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u4kEofIsHCnq"
      },
      "source": [
        "##Dropping features\n",
        "lab_df.drop([\"subject_id\",\"hadm_id\",\"icustay_id\", \"mort_icu\", \"mort_oneyr\", \"adult_icu\", \"admType_NEWBORN\"], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ednt42T18oQX"
      },
      "source": [
        "##TODO: Split the dataset into train/val/test. Note that we have already provided\n",
        "##the columns \"train\", \"test\", \"valid\" for you which splits the dataset into \n",
        "##training set, validation set and testing set. \n",
        "##Once you're done, remove the columns train, val and test from the dataset.\n",
        "\n",
        "lab_df.head()\n",
        "# x axis\n",
        "x_train = lab_df[lab_df.train==1]\n",
        "x_valid = lab_df[lab_df.valid==1]\n",
        "x_test = lab_df[lab_df.test==1]\n",
        "\n",
        "\n",
        "\n",
        "# y axis\n",
        "y_train = lab_df[lab_df.train==1]\n",
        "y_valid = lab_df[lab_df.valid==1]\n",
        "y_test = lab_df[lab_df.test==1]\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5sTPCWXRtvoS"
      },
      "source": [
        "x_train.drop(['test','valid','train','mort_hosp'], axis=1, inplace=True)\n",
        "x_train.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W_mOZGCGv_XZ"
      },
      "source": [
        "x_valid.drop(['test','valid','train','mort_hosp'], axis=1, inplace=True)\n",
        "x_valid.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kAo8LJF3wFI_"
      },
      "source": [
        "x_test.drop(['test','valid','train','mort_hosp'], axis=1, inplace=True)\n",
        "x_test.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yfqkdv4Lm-Bd"
      },
      "source": [
        "# Before Droping stuff!\n",
        "# Subset of Test\n",
        "x_chavos = x_test[x_test.age < 40]\n",
        "x_rucos = x_test[x_test.age >= 40]\n",
        "print(x_chavos.age.count() + x_rucos.age.count() - x_test.age.count())\n",
        "print(f'chavos: {x_chavos.age.count()} rucos: {x_rucos.age.count()} total: {x_test.age.count()}')\n",
        "# subset of test\n",
        "y_chavos = y_test[y_test.age<40]\n",
        "y_rucos  = y_test[y_test.age>=40]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-FPyNgsVvMt1"
      },
      "source": [
        "y_train = y_train['mort_hosp']\n",
        "y_valid = y_valid['mort_hosp']\n",
        "y_test = y_test['mort_hosp']\n",
        "\n",
        "# Subset of test\n",
        "\n",
        "y_chavos = y_chavos['mort_hosp']\n",
        "y_rucos = y_rucos['mort_hosp']"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_1nXBc538o65"
      },
      "source": [
        "##TODO: Normalize the data in train/val/test. Be sure to fit StandardScaler to the training dataset only! \n",
        "\n",
        "scaler = StandardScaler().fit(x_train)\n",
        "\n",
        "train_sc = scaler.transform(x_train)\n",
        "test_sc = scaler.transform(x_test)\n",
        "valid_sc = scaler.transform(x_valid)\n",
        "\n",
        "#Test Subset\n",
        "\n",
        "chavos_sc = scaler.transform(x_chavos)\n",
        "rucos_sc = scaler.transform(x_rucos)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5AergCVix2er"
      },
      "source": [
        "##TODO: Problem 2.5, 2.6 - Train a Logistic Regression model \n",
        "##      (with solver = 'libnear') to predict mortality \n",
        "##      given the remaining features available. \n",
        "\n",
        "# C = [0.1, 0.25, 1]\n",
        "# penalty = ['l1', 'l2']\n",
        "solver = 'liblinear'\n",
        "max_iter=2000\n",
        "logreg = LogisticRegression\n",
        "\n",
        "penalty='l1'\n",
        "C=0.10\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "\n",
        "C=0.25\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "C=1.00\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "\n",
        "penalty='l2'\n",
        "C=0.10\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "\n",
        "C=0.25\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "C=1.00\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w19QFKzxAZ4i"
      },
      "source": [
        "# Now we're going to use C=1 and Penalty L2\n",
        "\n",
        "my_logreg=logreg(solver='liblinear', C=1, penalty='l2', max_iter = 2000).fit(train_sc, y_train)\n",
        "print(f'c=1, penalty=l2 score={my_logreg.score(valid_sc,y_valid)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mgnlWtZnjm-"
      },
      "source": [
        "# For last problem (double checking!)\n",
        "\n",
        "penalty='l2'\n",
        "C=1\n",
        "# Training\n",
        "my_logreg=logreg(solver='liblinear', C=C, penalty=penalty, max_iter = 2000).fit(train_sc, y_train)\n",
        "\n",
        "# Validating against Chavos\n",
        "AUC=roc_auc_score(y_chavos, my_logreg.predict_proba(chavos_sc)[:,1])\n",
        "score=my_logreg.score(chavos_sc,y_chavos)\n",
        "print(f'Chavos with C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "\n",
        "# Validating against Rucos\n",
        "AUC=roc_auc_score(y_rucos, my_logreg.predict_proba(rucos_sc)[:,1])\n",
        "score=my_logreg.score(rucos_sc,y_rucos)\n",
        "print(f'Rucos with C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JCp95uVXLS22"
      },
      "source": [
        "##TODO: Problem 2.7 - Which of the following features are among the top 5 most \n",
        "##positive features, based on the coefficients of the logistic regression model?\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JF9h6JY7VT-p"
      },
      "source": [
        "# Extracting coefficients and mapping with their names\n",
        "# converted into dataframe for easy manipulation\n",
        "\n",
        "coef = pd.DataFrame(columns=['name','value'])\n",
        "my_logreg.coef_\n",
        "X=x_train.columns\n",
        "\n",
        "for i,val in enumerate(my_logreg.coef_[0]):\n",
        "  coef=coef.append({'name':x_train.columns[i],\n",
        "                                    'value':val\n",
        "                                    }, ignore_index=True)\n",
        "\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Kn67zD74V-40"
      },
      "source": [
        "# 5 Top predictive positive features\n",
        "coef[coef.name=='albumin']\n",
        "coef.sort_values(by='value',ascending=False).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EcbpRd-LUe3"
      },
      "source": [
        "##TODO: Problem 2.8 - Which of the following features are among the top 5 most \n",
        "##negative features, based on the coefficients of the logistic regression model?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oZ5NJHWGgPQx"
      },
      "source": [
        "# 5 Top predictive negative features\n",
        "coef.sort_values(by='value',ascending=True).head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R0u2eZw0_Ov3"
      },
      "source": [
        "## Question 3\n",
        "\n",
        "Predicting hospital mortality from clinical notes\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exk56Quh9HqL"
      },
      "source": [
        "note_df.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd7Uzlj7xTTc"
      },
      "source": [
        "note_df.drop([\"subject_id\",\"hadm_id\",\"icustay_id\", \"mort_icu\", \"mort_oneyr\"], axis=1, inplace=True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GKGab1yIxYPX"
      },
      "source": [
        "##TODO: Split the dataset into train/val/test\n",
        "x_train = note_df[note_df.train == 1]\n",
        "x_valid = note_df[note_df.valid == 1]\n",
        "x_test = note_df[note_df.test==1]\n",
        "\n",
        "total = len(x_test)+len(x_train)+len(x_valid)\n",
        "if len(x_test)+len(x_train)+len(x_valid) == len(note_df):\n",
        "  print (f'X axis seems to be OK {total}')\n",
        "\n",
        "# Y axis\n",
        "y_train = note_df[note_df.train == 1].mort_hosp\n",
        "y_valid = note_df[note_df.valid == 1].mort_hosp\n",
        "y_test = note_df[note_df.test==1].mort_hosp\n",
        "\n",
        "total = len(y_test)+len(y_train)+len(y_valid)\n",
        "if len(y_test)+len(y_train)+len(y_valid) == len(note_df):\n",
        "  print (f'Y axis seems to be OK {total}')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w3_BKyQM7XBJ"
      },
      "source": [
        "print(f'train {len(x_train)}, validation {len(x_valid)}, test {len(x_test)}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k3S-Z05nsiNo"
      },
      "source": [
        "x_train.drop(['test','valid','train','mort_hosp'], axis=1, inplace=True)\n",
        "x_train.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AMifjGll5PcO"
      },
      "source": [
        "x_valid.drop(['test','valid','train','mort_hosp'], axis=1, inplace=True)\n",
        "x_valid.head(5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QxsDTqi_5QQ9"
      },
      "source": [
        "x_test.drop(['test','valid','train','mort_hosp'], axis=1, inplace=True)\n",
        "x_test.head(3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5doWs6ZLnmrX"
      },
      "source": [
        "##TODO: Fit a CountVectorizer with max_features = 5000 to the trianing dataset and generate features for train/val/test. \n",
        "# Vectorizing Validation Set"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fhbiWB2Wo7KU"
      },
      "source": [
        "# Vectorizing Validation Set\n",
        "vectorizer = CountVectorizer(max_features = 5000)\n",
        "\n",
        "train_sc = vectorizer.fit_transform(x_train.chartext)\n",
        "valid_sc = vectorizer.transform(x_valid.chartext)\n",
        "test_sc = vectorizer.transform(x_test.chartext)\n",
        "\n",
        "print(train_sc.shape)\n",
        "print(valid_sc.shape)\n",
        "print(test_sc.shape)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZVZ9ByAbx-U6"
      },
      "source": [
        "##TODO: Problem 3.1, 3.2 Train a Logistic Regression model (with solver = 'liblinear') to predict mortality given the remaining features available. \n",
        "\n",
        "C = [0.1,0.25,1]\n",
        "penalty = ['l1','l2']\n",
        "\n",
        "solver = 'liblinear'\n",
        "max_iter=2000\n",
        "logreg = LogisticRegression\n",
        "\n",
        "def pasuma(C,penalty):\n",
        "  my_logreg=LogisticRegression( C=C, \n",
        "                              penalty=penalty, \n",
        "                              solver=solver, \n",
        "                              max_iter = max_iter\n",
        "                              ).fit(train_sc, y_train)\n",
        "  AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "  score=my_logreg.score(valid_sc,y_valid)\n",
        "  print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "\n",
        "for p in penalty:\n",
        "  for c in C:\n",
        "    pasuma(C=c,penalty=p)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iMiAFdVv8kE0"
      },
      "source": [
        "my_logreg=LogisticRegression( C=0.1, \n",
        "                              penalty='l1', \n",
        "                              solver='liblinear', \n",
        "                              max_iter = 2000\n",
        "                              ).fit(train_sc, y_train)\n",
        "\n",
        "AUC=roc_auc_score(y_valid, my_logreg.predict_proba(valid_sc)[:,1])\n",
        "score=my_logreg.score(valid_sc,y_valid)\n",
        "\n",
        "print(f'With C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gBVI_MQu3dki"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "beRbOaOP9KY2"
      },
      "source": [
        "##TODO: Problem 3.3 Which of the following features are among the top 5 most \n",
        "##predictive positive words, based on the coefficients of the logistic regression model?\n",
        "\n",
        "# len(my_logreg.coef_[0])\n",
        "# X=x_train.columns\n",
        "# my_logreg.tol\n",
        "\n",
        "# x_train.chartext[1]\n",
        "\n",
        "# coef = pd.DataFrame(columns=['name','value'])\n",
        "# my_logreg.coef_\n",
        "# X=x_train.columns\n",
        "\n",
        "# for i,val in enumerate(my_logreg.coef_[0]):\n",
        "#   coef=coef.append({'name':x_train.columns[i],\n",
        "#                                     'value':val\n",
        "#                                     }, ignore_index=True)\n",
        "\n",
        "# my_logreg.coef_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0fKZpM-x9N_R"
      },
      "source": [
        "##TODO: Problem 3.4 Which of the following features are among the top 5 most \n",
        "##predictive negative words, based on the coefficients of the logistic regression model?"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fhKFPNlIAV-0"
      },
      "source": [
        "## Question 4\n",
        "\n",
        "Analysis of data and results"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DxyN7K3m_Wbp"
      },
      "source": [
        "##TODO: Problem 4.1 - people / mortality rate in different ethnic categorizations\n",
        "\n",
        "# total_deaths = sum(lab_df[lab_df.mort_hosp==1].count())\n",
        "# print(total_deaths)\n",
        "# lab_df[lab_df.mort_hosp==1].groupby('mort_hosp')['mort_hosp'].count()\n",
        "# lab_df.groupby('age')['mort_hosp'].count()\n",
        "etn = ['eth_asian','eth_black','eth_hispanic','eth_white','eth_other']\n",
        "more = 'mort_hosp'\n",
        "print(lab_df[lab_df[more]==1].groupby(etn)[more].count())\n",
        "# print(lab_df[lab_df[more]==0].groupby(etn)[more].count())\n",
        "\n",
        "print(lab_df.groupby(etn)[more].count())\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QJkDl7BsOLe9"
      },
      "source": [
        "muertos = lab_df[lab_df[more]==1].groupby(etn)[more].count()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nqedCs7OSx56"
      },
      "source": [
        "# print(f'other {732/3904}')\n",
        "# print(f'white {2637/19364}')\n",
        "# print(f'hispa {92/881}')\n",
        "# print(f'black {286/2581}')\n",
        "# print(f'asian {94/618}')\n",
        "# print()\n",
        "# print(f'Total {732/3904 + 2637/19364 + 92/881 + 286/2581 + 94/618}')\n",
        "\n",
        "# print(f'Total {3904 + 19364 + 881 + 2581 +618}')\n",
        "\n",
        "# lab_df[lab_df[more]==1][more].count()/lab_df[lab_df[more]==0][more].count()\n",
        "\n",
        "\n",
        "total_d = 0\n",
        "total_v = 0\n",
        "for et in etn:\n",
        "  ppl= lab_df[lab_df[et]==1]\n",
        "  alive = ppl[more].count()\n",
        "  # pp = lab_df[lab_df[et]==1][more].count()\n",
        "  death = ppl[ppl[more]==1][more].count()\n",
        "  print(f'{et} Entries {alive} Deaths  {death} MortalityRate {death/alive}')\n",
        "  total_d = total_d + death\n",
        "  total_v = total_v + alive\n",
        "\n",
        "print(total_d)\n",
        "print(total_v)\n",
        "print(total_d/total_v)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xRV_F6709e-C"
      },
      "source": [
        "##TODO: Problem 4.2 - plot histogram for ages"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p14sV8ZbIt83"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fNbxp_qE9hpb"
      },
      "source": [
        "##TODO: Problem 4.3 - plot histogram for mortality rates\n",
        "plt.hist(lab_df.age,bins=[20,30,40,50,60,70,80,90])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niSrx1AecIu-"
      },
      "source": [
        "\n",
        "\n",
        "# plt.hist(lab_df.age,bins=[20,30,40,50,60,70,80,90])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cJGp5DOi9jdy"
      },
      "source": [
        "##TODO: Problem 4.4 - retrain a model using C=1, penalty = l2 and evaluate AUC\n",
        "##and accuracy on the test set with age less than 40 and on the test set with\n",
        "##age greater than or equal to 40."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "biRfK9obgsfr"
      },
      "source": [
        "chavos = x_test[x_test.age < 40]\n",
        "rucos = x_test[x_test.age >= 40]\n",
        "print(chavos.age.count() + rucos.age.count() - x_test.age.count())\n",
        "print(f'chavos: {chavos.age.count()} rucos: {rucos.age.count()} total: {x_test.age.count()}')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KZijj-seir7-"
      },
      "source": [
        "# y axis\n",
        "y_test = lab_df[lab_df.test==1]\n",
        "y_chavos = y_test[y_test.age < 40]\n",
        "y_rucos = y_test[y_test.age >= 40]\n",
        "\n",
        "print(f'chavos: {y_chavos.age.count()} rucos: {y_rucos.age.count()} total: {y_test.age.count()}')\n",
        "\n",
        "y_chavos = y_chavos['mort_hosp']\n",
        "y_rucos = y_rucos['mort_hosp']\n",
        "\n",
        "print(len(y_chavos),len(y_rucos))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7A4x3bNfiSl4"
      },
      "source": [
        "# Re scaling for the new sets\n",
        "scaler = StandardScaler().fit(x_train)\n",
        "\n",
        "train_sc = scaler.transform(x_train)\n",
        "rucos_sc = scaler.transform(rucos)\n",
        "chavos_sc = scaler.transform(chavos)\n",
        "valid_sc = scaler.transform(x_valid)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-GwkXi-XkzE"
      },
      "source": [
        "# Now we're going to use C=1 and Penalty L2\n",
        "\n",
        "# C=1\n",
        "# penalty='l2'\n",
        "# my_logreg=logreg(solver='liblinear', C=1, penalty='l2', max_iter = 2000).fit(train_sc, y_train)\n",
        "\n",
        "AUC=roc_auc_score(y_chavos, my_logreg.predict_proba(chavos_sc)[:,1])\n",
        "score=my_logreg.score(chavos_sc,y_chavos)\n",
        "print(f'For Chavos (<40) with C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n",
        "\n",
        "AUC=roc_auc_score(y_rucos, my_logreg.predict_proba(rucos_sc)[:,1])\n",
        "score=my_logreg.score(rucos_sc,y_rucos)\n",
        "print(f'For Rucos (>=40) with C={C} & Penalty={penalty} Accurracy={score} AUC={AUC}\\n')\n"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}